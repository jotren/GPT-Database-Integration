{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c562edad-9354-4619-ab34-9970100aba25",
   "metadata": {},
   "source": [
    "# GPT Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dce0c4-2be1-4e7d-9595-678ed1fd3b2c",
   "metadata": {},
   "source": [
    "At some point Cognitive will want the chatbot that sits at the centre of the applications to be able to run calcualtions with uploaded files. This script will aim to give a assistant a task with some data in a csv and then see if it can solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d205a0c-114f-4b5e-b330-5e5db42c2c7c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f8158c-ff45-4a98-aba6-cab58190bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import sys\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.append('C:/projects/python/gpt-databasewrapper')\n",
    "\n",
    "GPT_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(\n",
    "  api_key=GPT_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff43ed-dd0c-4f2d-a603-fcccfe634848",
   "metadata": {},
   "source": [
    "### File Upload\n",
    "\n",
    "Going to use the famous titanic dataset and ask the assistant questions. **Note**: Once you upload a file, it will stay in your Open AI repository until you delete it. Be careful to upload loads of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a826813-4433-420f-8abe-45d200d4c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the file\n",
    "file = client.files.create(\n",
    "  file=open(\"../data/raw/titanic_dataset.csv\", \"rb\"),\n",
    "    purpose=\"user_data\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd46d20d-dc98-46da-81f7-ec6ceeb59f73",
   "metadata": {},
   "source": [
    "### Create Assistant\n",
    "\n",
    "Will the create the assistant, notice that we are using the \"code_interpreter\" to answer this questions. This allows the assistant to create some python code in the background to solve the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a26e68a-c89f-4571-b2b4-d01ef3b43d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Titanic Questions\",\n",
    "  description=\"You are a bot attempting to answer questions about some data regarding the sinking of the titanic.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e765a-8aa1-4ed4-99e7-b21546f27c9d",
   "metadata": {},
   "source": [
    "Once we have created the assistant, we then need to create the \"thread\". This represents the questions you would like to ask the machine about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6376c1c8-f91a-452b-8b17-d94adb934b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Based on this data, could you please tell me how many people survived/died on this section of the titanic?\",\n",
    "      \"attachments\": [\n",
    "        {\n",
    "          \"file_id\": file.id,\n",
    "          \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f72f45-981e-4d6d-8829-464f3566b205",
   "metadata": {},
   "source": [
    "We have submitted are set of questions, we now need to run the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23fdc088-2b98-4637-bf82-6468cd1add29",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6c33e-d8d7-494b-9b65-cbbe5e239aa5",
   "metadata": {},
   "source": [
    "### Check Query Run\n",
    "\n",
    "Once we create the run we need to monitor the results. It can take time to answer these types of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e19a203-dcd3-4595-ae49-231ba124f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Run Details: Run(id='run_YvcEMGrtDU5b4ju8k9gTAPTv', assistant_id='asst_5lF7PRvkEQ4oYm9fDb4HTMN1', cancelled_at=None, completed_at=1717153166, created_at=1717153155, expires_at=None, failed_at=None, incomplete_details=None, instructions=None, last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=1717153155, status='completed', thread_id='thread_6N8MsxcyhWl8Yb76RT81RBfs', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=231, prompt_tokens=3127, total_tokens=3358), temperature=1.0, top_p=1.0, tool_resources={})\n",
      "Message Content: [TextContentBlock(text=Text(annotations=[], value='According to the data:\\n\\n- **500** people survived.\\n- **809** people did not survive.\\n\\nIf you need any further analysis or details, feel free to ask!'), type='text')]\n",
      "Message Content: [TextContentBlock(text=Text(annotations=[], value=\"It looks like the dataset includes information about passengers on the Titanic, with columns such as `pclass`, `survived`, `name`, `sex`, `age`, among others. The key column for determining the number of survivors and non-survivors is `survived`, where `1` indicates the passenger survived and `0` indicates the passenger did not survive.\\n\\nLet's calculate the number of survivors and non-survivors:\"), type='text')]\n",
      "Message Content: [TextContentBlock(text=Text(annotations=[], value='Based on this data, could you please tell me how many people survived/died on this section of the titanic?'), type='text')]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def retrieve_run_details(thread_id, run_id):\n",
    "    return client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "\n",
    "# Start by getting initial run details\n",
    "run_details = retrieve_run_details(thread_id=thread.id, run_id=run.id)\n",
    "print(\"Initial Run Details:\", run_details)\n",
    "\n",
    "# Poll for updates on the run's status\n",
    "while run_details.status not in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "    time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "    run_details = retrieve_run_details(thread_id=thread.id, run_id=run.id)\n",
    "    print(\"Current Run Status:\", run_details.status)\n",
    "\n",
    "# Check final status and retrieve messages if completed\n",
    "if run_details.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    for message in messages.data:\n",
    "        print(\"Message Content:\", message.content)\n",
    "else:\n",
    "    print(\"Run did not complete successfully:\", run_details)\n",
    "    if 'error' in run_details:\n",
    "        print(\"Error Details:\", run_details.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb2230-3ae7-4a77-8110-85a4134e8c1d",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "If we inspect the result we can see that the GPT recognised the dataset, parsed the columns and then did a sum of the survival column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83b40789-bb5c-400a-9135-c1ffdd3fcbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the data:\n",
      "\n",
      "- **500** people survived.\n",
      "- **809** people did not survive.\n",
      "\n",
      "If you need any further analysis or details, feel free to ask!\n",
      "It looks like the dataset includes information about passengers on the Titanic, with columns such as `pclass`, `survived`, `name`, `sex`, `age`, among others. The key column for determining the number of survivors and non-survivors is `survived`, where `1` indicates the passenger survived and `0` indicates the passenger did not survive.\n",
      "\n",
      "Let's calculate the number of survivors and non-survivors:\n",
      "Based on this data, could you please tell me how many people survived/died on this section of the titanic?\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    content_blocks = message.content\n",
    "    for content_block in content_blocks:\n",
    "        text_content = content_block.text.value\n",
    "        print(text_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
